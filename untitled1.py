# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HJ39uIZ5Pt7F8Tf4e5KWDfB7p2eKGAR6
"""

!pip install transformers

import tensorflow as tf
from transformers import GPT2LMHeadModel, GPT2Tokenizer

tokenizer = GPT2Tokenizer.from_pretrained("gpt2-large")
model = GPT2LMHeadModel.from_pretrained("gpt2-large", pad_token_id=tokenizer.eos_token_id)
sentence = '10 big moments in Olympic Games history'

input_ids = tokenizer.encode(sentence, return_tensors='pt')
input_ids

# generate text until the output length (which includes the context length) reaches 50
output = model.generate(input_ids, max_length=9000000, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)
output

print(tokenizer.decode(output[0], skip_special_tokens=True))